[![Build Status](https://travis-ci.org/timolinn/hng.tech.svg?branch=master)](https://travis-ci.org/timolinn/hng.tech)

<div align="center">

![hng](https://res.cloudinary.com/iambeejayayo/image/upload/v1554240066/brand-logo.png)

<br>

</div>

# GPT2_conversational_analyis

## Conversational Analysis Report on GPT-2 Model

The GPT-2 model is a Natural language processing model, created by openai. It is a high-level NLP model that can be used for reading comprehension, text completion, summarization, translation, and question-answering when trained with a dataset.
The team task is to train and fine-tune the model with Kaggle ubuntu data and make report on the findings.


# Testing

-	Open on Google colab
-	importing libraries
-	The ubuntu data was downloaded using the Kaggle api (kaggle json provided for download)
-	cloning git repo to
-	installing necessary requirements
-	Download the model
-	Cleaning data
-	Parsing data to model
-	Encoding data
-	Training data
-	generate conversations on its own 
-	generate sample articles on its own base on the trained data.

### The model was finetuned by making changes to the model’s learning_rate, stop_after and the following flags
•	model_name = Model 345M remained constant
•	nsamples 
•	length 
•	temperature
•	top_k 

# Findings/Observations
Our findings and report can be accessed by the Report on GPT-2 Analysis written by @Dev_Spyder

Our team comprises of @GabbyPrecious, @Miebaka Woriaka, @enfinity, @BobbyX and @Dev_Spyder
Everyone contribute to the codes, and researching

We have three different file from the team and the report wriiten by @BobbyX and @Dev_Spyder 
